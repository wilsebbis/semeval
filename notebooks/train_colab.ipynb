{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CLARITY: SemEval 2026 — Training Notebook\n",
                "\n",
                "Works on **both Colab (GPU) and local**.\n",
                "\n",
                "| Config | Model | VRAM | Expected Task2 F1 |\n",
                "|--------|-------|------|-------------------|\n",
                "| `deberta_v3_base.yaml` | DeBERTa-v3-base | ~6GB | ~0.48–0.56 |\n",
                "| `deberta_v3_large.yaml` | DeBERTa-v3-large | ~16GB | ~0.56–0.65 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup Environment"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check GPU\n",
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    props = torch.cuda.get_device_properties(0)\n",
                "    vram = getattr(props, 'total_memory', getattr(props, 'total_mem', 0))\n",
                "    print(f\"VRAM: {vram / 1e9:.1f} GB\")\n",
                "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
                "    print(\"MPS (Apple Silicon) available\")\n",
                "else:\n",
                "    print(\"CPU only\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys\n",
                "\n",
                "# Detect environment\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "\n",
                "print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
                "\n",
                "if IN_COLAB:\n",
                "    # ═══════════════════════════════════════════════════════════════\n",
                "    # EDIT THIS: your GitHub repo URL (must push repo first!)\n",
                "    REPO_URL = \"https://github.com/wilsebbis/semeval.git\"\n",
                "    # ═══════════════════════════════════════════════════════════════\n",
                "    import subprocess\n",
                "    if not os.path.exists('/content/semeval'):\n",
                "        subprocess.run(['git', 'clone', REPO_URL, '/content/semeval'], check=True)\n",
                "    else:\n",
                "        subprocess.run(['git', '-C', '/content/semeval', 'pull'], check=True)\n",
                "    os.chdir('/content/semeval')\n",
                "    !pip install -q -e \".[dev]\" 2>&1 | tail -3\n",
                "else:\n",
                "    # Running locally — cd to project root\n",
                "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
                "        os.chdir(os.path.join(os.getcwd(), '..'))\n",
                "\n",
                "print(f\"Working dir: {os.getcwd()}\")\n",
                "\n",
                "# Verify\n",
                "from clarity.labels import EVASION_LABELS, CLARITY_LABELS, validate_labels\n",
                "validate_labels()\n",
                "print(f\"✓ {len(EVASION_LABELS)} evasion labels, {len(CLARITY_LABELS)} clarity labels\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "if not Path('data/train.csv').exists():\n",
                "    !git clone https://huggingface.co/datasets/ailsntua/QEvasion 2>/dev/null || echo \"Already cloned\"\n",
                "    !bash scripts/prepare_data.sh\n",
                "else:\n",
                "    print(\"Data already prepared.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "\n",
                "train = pd.read_csv(\"data/train.csv\")\n",
                "dev = pd.read_csv(\"data/dev.csv\")\n",
                "print(f\"Train: {len(train)} rows | Dev: {len(dev)} rows\")\n",
                "print(f\"\\nEvasion distribution:\")\n",
                "print(train[\"evasion_label\"].value_counts().to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Choose config ────────────────────────────────────────\n",
                "CONFIG = \"configs/deberta_v3_base.yaml\"           # T4 OK\n",
                "# CONFIG = \"configs/deberta_v3_large.yaml\"        # A100/L4\n",
                "# CONFIG = \"configs/deberta_v3_base_no_weights.yaml\"  # ablation\n",
                "# ─────────────────────────────────────────────────────────\n",
                "\n",
                "import yaml\n",
                "with open(CONFIG) as f:\n",
                "    cfg = yaml.safe_load(f)\n",
                "print(f\"Config: {CONFIG}\")\n",
                "for k, v in sorted(cfg.items()):\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m clarity.train \\\n",
                "    --config {CONFIG} \\\n",
                "    --data data/train.csv \\\n",
                "    --dev data/dev.csv \\\n",
                "    --task evasion"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "output_dir = cfg[\"output_dir\"]\n",
                "metrics_path = Path(output_dir) / \"metrics.json\"\n",
                "\n",
                "if metrics_path.exists():\n",
                "    with open(metrics_path) as f:\n",
                "        metrics = json.load(f)\n",
                "    for m in metrics:\n",
                "        ep = m.get('epoch', '?')\n",
                "        ev = m.get('evasion_macro_f1', 0)\n",
                "        cl = m.get('clarity_macro_f1', 0)\n",
                "        print(f\"  Epoch {ep}: Task2 F1={ev:.4f}, Task1 F1={cl:.4f}\")\n",
                "else:\n",
                "    print(\"No metrics found — check training output above.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Predict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "CKPT = f\"{output_dir}/best_model.pt\"\n",
                "DATA = \"data/dev.csv\"  # Change to data/test.csv for submission\n",
                "\n",
                "!python -m clarity.predict \\\n",
                "    --ckpt {CKPT} \\\n",
                "    --data {DATA} \\\n",
                "    --out submissions/predictions.csv \\\n",
                "    --evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "preds = pd.read_csv(\"submissions/predictions.csv\")\n",
                "print(f\"Predictions: {len(preds)} rows\")\n",
                "print(preds[\"evasion_pred\"].value_counts().to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Ensemble (Optional)\n",
                "\n",
                "Train 3 seeds, average logits → +1–3 F1 points."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "SEEDS = [42, 123, 2026]\n",
                "\n",
                "for seed in SEEDS:\n",
                "    out_dir = f\"checkpoints/ensemble_seed{seed}\"\n",
                "    print(f\"\\n{'='*60}\")\n",
                "    print(f\"Training seed {seed} -> {out_dir}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    !python -m clarity.train \\\n",
                "        --config {CONFIG} \\\n",
                "        --data data/train.csv \\\n",
                "        --dev data/dev.csv \\\n",
                "        --task evasion \\\n",
                "        --seed {seed} \\\n",
                "        --output_dir {out_dir}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ckpts = [f\"checkpoints/ensemble_seed{s}/best_model.pt\" for s in SEEDS]\n",
                "ckpts_str = \" \".join(ckpts)\n",
                "\n",
                "!python -m clarity.predict \\\n",
                "    --ckpt {ckpts[0]} \\\n",
                "    --ensemble_ckpts {ckpts_str} \\\n",
                "    --data data/dev.csv \\\n",
                "    --out submissions/ensemble_predictions.csv \\\n",
                "    --evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Download (Colab only)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if IN_COLAB:\n",
                "    from google.colab import files\n",
                "    files.download(\"submissions/predictions.csv\")\n",
                "else:\n",
                "    print(f\"Results: {os.path.abspath('submissions/predictions.csv')}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "T4",
            "name": "CLARITY SemEval 2026 — Training",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}