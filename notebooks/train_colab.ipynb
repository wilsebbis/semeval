{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# CLARITY: SemEval 2026 — A100 Training\n",
                "\n",
                "| Config | Model | Precision | VRAM | Expected F1 |\n",
                "|--------|-------|-----------|------|-------------|\n",
                "| `deberta_v3_base.yaml` | DeBERTa-v3-base | auto(bf16) | ~6GB | ~0.48–0.56 |\n",
                "| `deberta_v3_large.yaml` | DeBERTa-v3-large | bf16 | ~12-14GB | ~0.56–0.65 |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "print(f\"PyTorch: {torch.__version__}\")\n",
                "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    props = torch.cuda.get_device_properties(0)\n",
                "    vram = getattr(props, 'total_memory', getattr(props, 'total_mem', 0))\n",
                "    print(f\"VRAM: {vram / 1e9:.1f} GB\")\n",
                "    print(f\"bf16: {torch.cuda.is_bf16_supported()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os, sys\n",
                "\n",
                "try:\n",
                "    import google.colab\n",
                "    IN_COLAB = True\n",
                "except ImportError:\n",
                "    IN_COLAB = False\n",
                "\n",
                "if IN_COLAB:\n",
                "    REPO_URL = \"https://github.com/wilsebbis/semeval.git\"\n",
                "    if not os.path.exists('/content/semeval'):\n",
                "        !git clone {REPO_URL} /content/semeval\n",
                "    else:\n",
                "        !cd /content/semeval && git pull\n",
                "    os.chdir('/content/semeval')\n",
                "    %pip install -e \".[dev]\"\n",
                "    os.environ['HF_HOME'] = '/content/hf_cache'\n",
                "else:\n",
                "    if os.path.basename(os.getcwd()) == 'notebooks':\n",
                "        os.chdir(os.path.join(os.getcwd(), '..'))\n",
                "\n",
                "src_path = os.path.join(os.getcwd(), 'src')\n",
                "if src_path not in sys.path:\n",
                "    sys.path.insert(0, src_path)\n",
                "\n",
                "print(f\"Working dir: {os.getcwd()}\")\n",
                "from clarity.labels import EVASION_LABELS, validate_labels\n",
                "validate_labels()\n",
                "print(f\"✓ {len(EVASION_LABELS)} evasion labels\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "if not Path('data/train.csv').exists():\n",
                "    !git clone https://huggingface.co/datasets/ailsntua/QEvasion 2>/dev/null || true\n",
                "    !bash scripts/prepare_data.sh\n",
                "else:\n",
                "    print(\"Data ready.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "train = pd.read_csv('data/train.csv')\n",
                "dev = pd.read_csv('data/dev.csv')\n",
                "print(f\"Train: {len(train)} | Dev: {len(dev)}\")\n",
                "print(train['evasion_label'].value_counts().to_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ── Pick config ──\n",
                "# CONFIG = \"configs/deberta_v3_base.yaml\"           # T4/Mac\n",
                "CONFIG = \"configs/deberta_v3_large.yaml\"             # A100\n",
                "# CONFIG = \"configs/deberta_v3_large_a100.yaml\"      # A100 alt\n",
                "\n",
                "import yaml\n",
                "with open(CONFIG) as f:\n",
                "    cfg = yaml.safe_load(f)\n",
                "print(f\"Config: {CONFIG}\")\n",
                "for k, v in sorted(cfg.items()):\n",
                "    print(f\"  {k}: {v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m clarity.train \\\n",
                "    --config {CONFIG} \\\n",
                "    --data data/train.csv \\\n",
                "    --dev data/dev.csv \\\n",
                "    --task evasion \\\n",
                "    --debug_text"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluate"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "output_dir = cfg['output_dir']\n",
                "mp = Path(output_dir) / 'metrics.json'\n",
                "if mp.exists():\n",
                "    m = json.load(open(mp))\n",
                "    for h in m.get('history', []):\n",
                "        print(f\"  Epoch {h.get('epoch','?')}: F1={h.get('evasion_macro_f1',0):.4f}, loss={h.get('val_loss',0):.4f}\")\n",
                "    print(f\"Best F1: {m.get('best_f1', 0):.4f}\")\n",
                "else:\n",
                "    print('No metrics found.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Predict"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m clarity.predict \\\n",
                "    --ckpt {output_dir}/best_model.pt \\\n",
                "    --data data/dev.csv \\\n",
                "    --out submissions/predictions.csv \\\n",
                "    --evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Ensemble (3 seeds)\n",
                "Train seeds 43 & 44, then average logits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "for seed_cfg in ['configs/deberta_v3_large_seed43.yaml',\n",
                "                 'configs/deberta_v3_large_seed44.yaml']:\n",
                "    print(f\"\\n{'='*60}\\nTraining: {seed_cfg}\\n{'='*60}\")\n",
                "    !python -m clarity.train --config {seed_cfg} --data data/train.csv --dev data/dev.csv --task evasion"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!python -m clarity.ensemble \\\n",
                "    --ckpts \\\n",
                "        checkpoints/deberta_v3_large/best_model.pt \\\n",
                "        checkpoints/deberta_v3_large_seed43/best_model.pt \\\n",
                "        checkpoints/deberta_v3_large_seed44/best_model.pt \\\n",
                "    --data data/dev.csv \\\n",
                "    --out submissions/ensemble_predictions.csv \\\n",
                "    --task evasion \\\n",
                "    --evaluate"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Download"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if IN_COLAB:\n",
                "    from google.colab import files\n",
                "    files.download('submissions/predictions.csv')\n",
                "    if Path('submissions/ensemble_predictions.csv').exists():\n",
                "        files.download('submissions/ensemble_predictions.csv')\n",
                "else:\n",
                "    print(f\"Results: {os.path.abspath('submissions/')}\")"
            ]
        }
    ],
    "metadata": {
        "accelerator": "GPU",
        "colab": {
            "gpuType": "A100",
            "name": "CLARITY SemEval 2026 — A100 Training",
            "provenance": []
        },
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}